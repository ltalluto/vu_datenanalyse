---
title: "The Basics"
author: "Lauren Talluto"
date: "13.01.2025"
output:
  slidy_presentation:
    theme: cerulean
    toc_depth: 2
    css: ../assets/rmd_style.css
    self_contained: false
    lib_dir: lib
---


```{r setup, include=FALSE}
# knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.width=5.5, fig.height=5.5, collapse = TRUE, comment = "##", dev="png")
library(knitr)
library(kableExtra)
data(penguins, package = "palmerpenguins")
penguins = as.data.frame(penguins)
penguins = penguins[complete.cases(penguins),]

library(RColorBrewer)
cols = brewer.pal(8, "Set1")

```


## Course Introduction

* We will cover two major branches of stats
* **Descriptive** statistics seeks to summarize natural variation in some variable/quantity of interest
   - e.g., What is the typical summer temperature of Alpine lakes in Tirol? 
   - How much variability is there in the temperature?
* **Inferential** statistics uses the laws of probability, combined with observations, to test hypotheses
   - Lakes from one region/ecozone are colder than lakes from another.

## Course Introduction

### Course structure
* Each day will be split between lectures and exercise sessions
* During exercises, we will split into smaller groups and work through problems
* Grading: 40% participation, 60% protocols

### Website and course materials

* The [course website](https://flee-group.github.io/vu_datenanalyse) has the course schedule and other information.
* The [students' Github repository](https://github.com/flee-group/vu_datenanalyse_students) includes data and scripts for all of the exercises


## Introduction to R

* `R` is two things:
   1. A statistical programming language
   2. A software package implementing the R language (available at [https://cran.r-project.org/](https://cran.r-project.org/))
* `RStudio` is a comprehensive working environment for R ([https://rstudio.com/products/rstudio/](https://rstudio.com/products/rstudio/))
   - An editor, for writing R programs
   - Tools to help you write and analyse code
   - An R console and interpreter


## Helpful vocabulary

* **console**: A window where you can type commands and view (text) results and output
* **interpreter**: Software that translates R commands into instructions for your computer in real time
* **script**: a text file containing a program, or series of commands
   - can be run **interactively** (sending commands one at a time to the console)
   - or in **batch mode** (all commands run, one after the other)
* **working directory**: location on your computer where R will search for files, data, etc.

Any code that is given to you will assume your working directory is set to the **unit** you are working on. So, for today's exercises, you should run the following in the console: `setwd("unit_1")`.


## Recommendations
* Create an RStudio project to organize your work for the course (File => New Project).
* Store all files in the project folder (your project will be **self-contained**).
* Save related commands together in a script.
* Annotate your code with comments. Write more comments than you need.
   - In R, anything after the `#` character is a comment and will be ignored by the interpreter.

   
   
   

## Variables

<div class="left lt">
* A **variable** is a name that points to some data. 
  - Variable names can contain lower- or upper-case letters, numbers, and the `_` symbol.
  - Names must start with letters and (when possible) should be descriptive
* Variables are given values by **assignment** using either the `=` or `<-` symbol

### Recommendations
* Use descriptive variable names instead of comments.
* Avoid 1- and 2- letter names.
* Separate words with underscores.
* Use a consistent assignment operator (`=` or `<-`, not both)
</div>

<div class="right rt">

```{r error=TRUE}
# Comments in R start with the # symbol
# anything after # will not be executed
# Comments are a useful way to annotate your code so you know what is 
# happening

# Legal variable names
x = 1
y0 = 5
time_of_day = "20:15"
dayOfWeek <- "Monday"

# bad!
# d is the diversity in our site, in species
d = 8

# better!
site_diversity = 8


# errors
0y = 5
my name = "Lauren"
```

</div>


## Data types

* `numeric`: integers and floating-point (decimal) numbers
* `logical`: yes/no, true/false data; in R represented by the special values `TRUE` and `FALSE`
	- `T` and `F` (no quotes) can be used as shortcuts for `TRUE`/`FALSE`, but you should avoid this!
* `character`: strings, text
* `factor`: special variable type for categorical (nominal & ordinal) data



## Operators

<div class="left lt">
We use **operators** to perform computations on variables and constants

* Assignment: `=`, `<-`
* Math: `+`, `-`, `*`, `/`, `^`, `%%`
* Comparison: `==`, `!=`, `<`, `>`, `<=`, `>=`
</div>

<div class="right rt">

```{r}
# assignment
x = 5

# math
x + 2
(3 + x) * 2
3^2
10 %% 3

# comparison
x < 7
x == 5.1

```

</div>

## Logic

<div class="left lt">
* Logical comparisons can be made with and (`&`), or (`|`), and not (`!`).

</div>

<div class="right rt">

```{r}
# and: both must be true
TRUE & TRUE
TRUE & FALSE
FALSE & FALSE

# or: only one needs to be true
TRUE | FALSE
FALSE | FALSE

# not: returns the opposite
!FALSE
```

</div>




## Logic

<div class="left lt">
* Logical comparisons can be made with and (`&`), or (`|`), and not (`!`).
* You can use logic to help your script make decision based on the outcome of a computation

</div>

<div class="right rt">

```{r}
# making decisions
x = 2^15 + 1
if(x > 100) {
	print("x is big")
} else {
	print("x is small")
}

if(x > 100 & x %% 2 == 0) {
	print("x is big and even")
} else {
	print("x is either small or an odd number")
}
```

</div>


## Functions

<div class="left lt">
* **Functions** take a series of **arguments** (which can be variables or constants).
* The function performs computations on the arguments.
* Functions can **return** a result, have **side-effects**, or both.

**Mathematical functions**

* `sin()`, `cos()`
* `log()`, `exp()`, `sqrt()`

Get help on a function with `?` or `help()`, for example: `?log` or `help(log)`.
If you don´t know a function´s name, you can search for a (likely/suspected) string in its name with `??`.


</div>

<div class="right rt">

```{r}
x = 5

# The print() function takes one or more arguments
#.      in this case the variable x
# It returns no value, but has the side effect of printing the 
# value of x to the screen
print(x)

# compute the natural logarithm of x, store it in y, then print the result
# How do I know it is the natural log?
y = log(x)
print(y)

# functions can take multiple arguments, and arguments can be named
# here we change the base of the logarithm
log(x, base = 10)
```

</div>



## Basic data structures: vectors

<div class="left lt">
* A **data structure** is a way of organizing multiple pieces of data into a single variable
* Can get very complex; we will start with the two most important types
* A `vector` holds one or more values of a single data type
    - Vectors can be created using the concatenate function `c()`
</div>

<div class="right rt">

```{r}
# The c() function stands for concatenate
# it groups items together into a vector
(five_numbers = c(3, 2, 8.6, 4, 9.75))

# create a vector of type character
colours = c("red", "red", "blue", "green", "red")

# can also create sequences and repeats directly into a vector
(one_to_ten = 1:10)
(count_by_threes = seq(0, 15, 3))
rep(0, 3)

```

</div>



## Basic data structures: vectors

<div class="left lt">
* A `vector` holds one or more values of a single data type
    - Vectors can be created using the concatenate function `c()`
    - You can **subset** vectors using `[]`

</div>

<div class="right rt">

```{r}

# Get part of a vector using []
five_numbers[3]
five_numbers[3:5]
five_numbers[c(1,4)]
```
</div>

## Basic data structures: vectors

<div class="left lt">
* A `vector` holds one or more values of a single data type
    - Vectors can be created using the concatenate function `c()`
    - You can **subset** vectors using `[]`
	- Other helpful functions can let you examine vectors
</div>

<div class="right rt">

```{r}
# get vector length
length(five_numbers)

# testing and coersion
x = 5.5
is.vector(x) ## even a single value is a vector in R
is.integer(x)
as.integer(x)


```

</div>





## Basic data structures: data frames

<div class="left lt">
* A `data.frame` holds tabular data
   - Each `row` of a data frame is a single **case** (i.e., an observation)
   - Each `column` of a data frame is a single variable (i.e., a `vector`, all the same data type)
* `head` shows the first few rows of a data frame

</div>

<div class="right rt">
   
```{r, results = "hide"}
# Load a dataset named 'penguins' and 
# convert it to a data frame
# this dataset comes from a package, "palmerpenguins"
data(penguins, package = "palmerpenguins")
penguins = as.data.frame(penguins)
head(penguins)
```

```{r echo = FALSE, results = 'asis'}
kable_styling(kable(head(penguins)), font_size = 12)
```



</div>


## Working with data frames

* `View` shows the data frame in a graphical window
* `str` gives you a summary of the **str**ucture of the data

```{r}
str(penguins)
```

## Working with data frames

* `nrow`, `ncol`, `dim` give you dimensions of the data frame

```{r}
# data frame dimensions
nrow(penguins)
ncol(penguins)
dim(penguins)
```


## Working with data frames

* Access an individual variable using `$` or `[]`
```{r, results = "hide"}
# accessing a variable by name
penguins$bill_length_mm

# accessing a variable by position
penguins[,1] # [,1] get every row in the first column
```

```{r}
# accessing a variable by name, and subsetting rows
penguins[1:10,"bill_length_mm"] # another way to access by name, gets the first 10 entries


```

### Code Style
* Here we show 3 ways of accessing a column (`$bill_length_mm`, `[,1]`, `[, 'bill_length_mm']`).
* Are any of these preferable to the others? Why?

## Working with data frames

* We saw on the last slide there are some NAs in the data, representing missing values.
* Many analyses fail with NAs. We must either remove them or instruct our analysis how to deal with them.
* Here we use `complete.cases`, which returns the rown numbers of all rows that do not contain *any* NAs.

```{r}
# There is an NA in this vector
penguins[1:10,"bill_length_mm"] 

# getting rid of NA values
# DANGER - this will erase the original penguins, make sure you mean to do this!
penguins = penguins[complete.cases(penguins),]
```



## Working with data frames

The variable `species` is a factor, representing a categorical variable with a fixed set of levels.

```{r}
str(penguins)
```

Useful functions for factors include `levels` and `table`.

```{r}
levels(penguins$species)
table(penguins$species)
```



## Graphics in R

R currently has two dominant graphical engines

<div class="left lt">

### Base graphics
* Built in to R.
* Simple to use
* Relatively easy syntax
* Plots usually need a lot of customization before they are finished

</div>

<div class="right rt">

### ggplot2
* A package you must install.
* More complex syntax
* Produces publication-quality graphics with less customization needed.
* Plots can be saved in a variable, with customization added as needed.

</div>




## Histograms: Base graphics
<div class="left lt">

* The workhorse function is `hist`

```{r eval = FALSE}
# generate some random numbers from the lognormal distribution
my_var = rlnorm(1000, log(10), 0.5)
hist(my_var)
```

</div>

<div class="right rt">
```{r echo = FALSE}
# generate some random numbers from the lognormal distribution
my_var = rlnorm(1000, log(10), 0.5)
hist(my_var)
```
</div>


## Histograms: Base graphics

<div class="left lt">
* The workhorse function is `hist`

The defaults are not very nice, so lets improve things

* `main = ""` disables the title
* `xlab` and `ylab` control axis labels
* `breaks` controls the number of bins in the histogram
* `col` sets the color of the bars
* `border` sets the color of the borders (`NA`: no border)

```{r eval = FALSE}
hist(my_var, main = "", xlab="Variable of interest", ylab = "Frequency", 
	 breaks = 20, col="#999999", border=NA)
```

</div>

<div class="right rt">
```{r echo = FALSE}
hist(my_var, main = "", xlab="Variable of interest", ylab = "Frequency", 
	 breaks = 20, col="#999999", border=NA)
```

</div>

## Colors

* R supports colors using the common HTML color coding: `#RRGGBB`
	- RR, GG, BB are the amounts of red, green, and blue
	- each ranges from `00` (none) to `FF` (most)
	- [Color pickers](https://www.w3schools.com/colors/colors_picker.asp) online help you translate a color in real life to a coded color
* R also has 657 named colors: `col = rosybrown`
* see the `colors()` function for the names

```{r}
head(colors())
```

## Colors

```{r echo = FALSE, fig.width=35, fig.height=18}
library(ggdark)
d = expand.grid(xl = 1:27, yb = 25:1)
d$colors = NA
d$colors[1:657] = colors()
d = d[complete.cases(d),]
par(mar = c(0,0,0,0))
plot(0,0, xlim = c(1,28), ylim = c(1,26), type = 'n', axes = FALSE, xlab = "", ylab = "")
with(d, rect(xl, yb, 1+xl, 1+yb, col = colors, border = NA))
with(d, text(xl, yb + 0.5, colors, col = invert_color(colors), cex = 1, adj = 0))
```




## Populations & Samples
<div class="left lt">
* A **population** is the unit about which we want to learn about.
  - e.g., all the trees in a forest
</div>

<div class="right rt">
![](img/forest1.png)
</div>


## Populations & Samples
<div class="left lt">
* A **population** is the unit about which we want to learn about.
  - e.g., all the trees in a forest
* A **sample** is a subset of a population that is observed with the goal of obtaining knowledge about a population.
	- We use statistics to describe, analyse, or perform inference about a population from a sample.

</div>

<div class="right rt">
![](img/forest2.png)

</div>



## Populations & Samples

<div class="left lt">

### Considerations when sampling:
* Select, e.g., 7 trees at random
* Samples must be taken carefully so that they are representative of the entire population!
* Gold standard: sample sizes must be **large** and drawn **randomly** from the population
* **Experimental design**: designing the sample such that it represents the desired population
</div>

<div class="right rt">

![](img/forest2.png)

</div>


## Describing populations and samples
<div class="left lt">
* We can visualise the distribution of values within a population using a **histogram**

> - We use **summary statistics** to describe the values numerically.
> - In practise, we must estimate population statistics via sample statistics.
> - We can formally describe the shape of the distribution of values using special statistics called **moments**.

</div>

<div class="right rt">

```{r echo=FALSE, message=FALSE}
library(ggplot2)

p1 = ggplot(data.frame(my_var), aes(x=my_var)) + geom_histogram(bins = 30) + ylab("Frequency") + xlab("Variable of Interest")
p1
```

</div>






## Summary statistics: location

<div class="left lt">

* **First moment**: Arithmetic mean. 

The population mean ($\mu$) can be approximated with the **sample mean**:

$$
\mu \approx \bar{x} = \frac{1}{n}\sum_{i=1}^n x_i
$$

</div>

<div class="right rt">
```{r echo=FALSE}
lwd=2
p2 = p1 + geom_vline(xintercept = mean(my_var), col = cols[1])
p2
```

```{r}
mean(my_var)
```

</div>



## Summary statistics: location

<div class="left lt">

* **First moment**: Arithmetic mean. 

### Other location statistics

The mean can be strongly influenced by outliers.

* median: The 50% quantile (i.e., half the values of x are above the median, half below)

</div>

<div class="right rt">
```{r echo=FALSE}
p2 = p2 + geom_vline(xintercept = median(my_var), col = cols[2])
p2
```

```{r}
median(my_var)

```

</div>



## Summary statistics: location

<div class="left lt">

* **First moment**: Arithmetic mean. 

### Other location statistics

The mean can be strongly influenced by outliers.

* median: The 50% quantile (i.e., half the values of x are above the median, half below)
* mode: the most common value, the "peak" of a distribution

</div>

<div class="right rt">
```{r echo=FALSE}
my_hist = hist(my_var, breaks = 30, plot = FALSE)
mode_index = which.max(my_hist$counts)
md = my_hist$mids[mode_index]

p2 = p2 + geom_vline(xintercept = median(md), col = cols[3])
p2
```

</div>




## Summary statistics: location

<div class="left lt">

* **First moment**: Arithmetic mean. 

### Other location statistics

The mean can be strongly influenced by outliers.

* median: The 50% quantile (i.e., half the values of x are above the median, half below)
* mode: the most common value, the "peak" of a distribution
* How to compute the mode? Use `hist`!
</div>

<div class="right rt">

```{r}
# mode
mode(my_var) # wrong!

# we can use the histogram function to approximate the sample mode
# WARNING: changing the number of breaks can have a 
# large impact on the results
my_hist = hist(my_var, breaks = 30, plot = FALSE)

# the mids variable gives you the midpoint of each bin
# counts gives you the count each bin
# cbind shows them together in columns
cbind(bar_midpoint = my_hist$mids, count = my_hist$counts)
```

</div>


## Summary statistics: location

<div class="left lt">

* **First moment**: Arithmetic mean. 

### Other location statistics

The mean can be strongly influenced by outliers.

* median: The 50% quantile (i.e., half the values of x are above the median, half below)
* mode: the most common value, the "peak" of a distribution
* How to compute the mode? Use `hist`!
</div>

<div class="right rt">

```{r}
# use which.max to find out which count index (which bar) is the largest
# then take that midpoint -- this is the mode
(mode_index = which.max(my_hist$counts))
my_hist$mids[mode_index]
```

</div>








## Summary statistics: location

<div class="left lt">

* **First moment**: Arithmetic mean. 

### Other location statistics

* minimum, maximum values
* quantiles: the p-th quantile of x is the value of x such that p% of values are beneath the quantile
   - commonly used: (2.5%, 97.5%), 50%, (25%, 75%)

### Comparing variables

We can compare variables in a way that is *location independent* by **centering** (subtracting the mean)


</div>

<div class="right rt">

```{r}
c(min(my_var), max(my_var))
range(my_var)

quantile(my_var, 0.4)

# Centre the variable
# note! arithmetic operators like `-` are vectorized!
my_var_ctr = my_var - mean(my_var)
mean(my_var_ctr)

```

</div>





## Summary statistics: dispersion (or scale)

<div class="left lt">


* **Second moment**: Variance ($\sigma^2$)

$$
\sigma^2 = \frac{1}{N}\sum_{i=1}^N (X_i-\mu)^2
$$


We can estimate $\sigma^2$ using the **sample variance**:

$$
\sigma^2 \approx s^2 = \frac{1}{n-1}\sum_{i=1}^n (x_i -\bar{x})^2
$$

It is convenient to talk about the scale of $x$ in the same units as $x$ itself, so we use the (population or sample) **standard deviation**:

$$
\sigma = \sqrt{\sigma^2} \approx s = \sqrt{s^2}
$$


</div>
<div class="right rt">

```{r echo=FALSE}
sdata = data.frame(
	xm = mean(my_var),
	x = mean(my_var) + sd(my_var),
	xe = mean(my_var) - sd(my_var),
	y = 50
)
p3 = p1 + geom_point(data = sdata, aes(x=xm, y =y)) + 
	geom_segment(data = sdata, aes(x = x, xend = xe, y = y, yend = y), col = cols[1])
p3
```

</div>


## Summary statistics: dispersion (or scale)

<div class="left lt">


* **Second moment**: Variance ($\sigma^2$)

$$
\sigma^2 = \frac{1}{N}\sum_{i=1}^N (X_i-\mu)^2
$$


We can estimate $\sigma^2$ using the **sample variance**:

$$
\sigma^2 \approx s^2 = \frac{1}{n-1}\sum_{i=1}^n (x_i -\bar{x})^2
$$

It is convenient to talk about the scale of $x$ in the same units as $x$ itself, so we use the (population or sample) **standard deviation**:

$$
\sigma = \sqrt{\sigma^2} \approx s = \sqrt{s^2}
$$


</div>
<div class="right rt">

```{r}
# Population variance -- biased if x is a sample!
# one-line version:
# sum((my_var - mean(my_var))^2)/length(my_var)

N = length(my_var)
sq_dev = (my_var - mean(my_var))^2
sum(sq_dev)/N

# These R functions always produce the sample variance and sd
var(my_var)
sd(my_var)


```
</div>



## Summary statistics: dispersion (or scale)

<div class="left lt">

### Other dispersion statistics

* range: `max(x) - min(x)`
* interquartile range (IQR): the difference between the third and first quartiles
* coefficient of variation (CV): 
$$
\frac{s}{|\bar{x}|}
$$


</div>
<div class="right rt">



```{r}
# the range function gives you the min and max
# Take the difference to get the statistical range
diff(range(my_var))
max(my_var) - min(my_var)

IQR(my_var)
quantile(my_var, 0.75) - quantile(my_var, 0.25)

# coefficient of variation can be done manually
sd(my_var)/mean(my_var)
```
</div>

## Summary statistics: higher moments
<div class="left lt">

### Asymmetry: skewness

Is the distribution weighted to one side or the other?

$$
\mathrm{skewness} = \frac{\sum_{i=1}^{n}(x_i-\bar{x})^3}{(n-1)s^3}
$$

```{r, echo = FALSE}
xx = seq(0, 1, length.out=100)
y1 = dbeta(xx, 2, 8)
y2 = dbeta(xx, 8, 2)
y3 = dbeta(xx, 5, 5)
y1 = y1/max(y1)
y2 = y2/max(y2)
y3 = y3/max(y3)

layout(matrix(2:1, ncol=1), heights = c(0.2, 1))
par(mar=c(2.5, 2.5, 0, 0.5), oma = c(0,0,0,0), mgp=c(1, 0.5, 0))
plot(xx, y3, type='l', col=cols[1], xaxt='n', yaxt='n', ylab="Density", lwd=2, xlab="Variable value", bty='l')
lines(xx, y1, type='l', col=cols[2], lwd=2)
lines(xx, y2, type='l', col=cols[3], lwd=2)
par(mar=c(0,0,0.5,0.5))
plot(0,0,type='n', axes=FALSE, xlab='', ylab='')
legend("topleft", legend = c("skew = 0", "right (positive) skew", "left (negative) skew"), cex = 0.8, lwd=2, bty='n', col=cols[1:3])

```

</div>
<div class="right rt">

### Tailedness: kurtosis

How fat are the tails relative to a normal distribution?

$$
\mathrm{kurtosis} = \frac{\sum_{i=1}^{n}(x_i-\bar{x})^4}{(n-1)s^4}
$$


```{r, echo = FALSE}
y1 = dnorm(xx, 0.5, 0.15)
y2 = dbeta(xx, 15, 15)
y3 = dbeta(xx, 3, 3)
# y1 = y1/max(y1)
# y2 = y2/max(y2)
# y3 = y3/max(y3)

# layout(matrix(1:2, nrow=1), widths = c(1, 0.5))
par(mar=c(2.5, 2.5, 0.5, 0), oma = c(0,0,0,0), mgp=c(1, 0.5, 0))
plot(xx, y1, type='l', col=cols[1], xaxt='n', yaxt='n', ylab="Density", lwd=2, xlab="Variable value", bty='l', ylim=c(0, max(y2)))
lines(xx, y2, type='l', col=cols[2], lwd=2)
lines(xx, y3, type='l', col=cols[3], lwd=2)
# par(mar=c(0,0,0.5,0.5))
# plot(0,0,type='n', axes=FALSE, xlab='', ylab='')
legend("topright", legend = c("mesokurtic (normal distribution)", 
                            "leptokurtic (positive kurtosis)", 
                            "platykurtic (negative kurtosis)"), lwd=2, bty='n', 
				col=cols[1:3], cex = 0.8)

```


</div>




## Another way to visualise a sample: boxplots

<div class="left lt">

* **Boxplots** (sometimes **box-and-whisker** diagrams) summarize key statistics.
	- median
	- first and third quartiles (hinges)
	- approx. 95% confidence interval for median (notch)
	- min/max (or quartile + 1.5*IQR) (whiskers)
* They are very useful for comparing variables among groups.
* Base graphics: we use the `boxplot` function
* `y ~ group` is a special data type called a `formula`

</div>

<div class="right rt">

```{r}
boxplot(body_mass_g ~ species, data = penguins, boxwex=0.4, notch = TRUE)
```


</div>


## More on boxplots

<div class="left lt">

* **Boxplots** (sometimes **box-and-whisker** diagrams) summarize key statistics.
	- median
	- first and third quartiles (hinges)
	- approx. 95% confidence interval for median (notch)
	- min/max (or quartile + 1.5*IQR) (whiskers)
* They are very useful for comparing variables among groups.
* Base graphics: we use the `boxplot` function
* `y ~ group` is a special data type called a `formula`

</div>

<div class="right rt">

```{r, eval = FALSE}
boxplot(body_mass_g ~ species, data = penguins, boxwex=0.4, notch = TRUE)
```

```{r, echo = FALSE}
boxplot(body_mass_g ~ species, data = penguins, boxwex=0.4, notch = TRUE)
rng = range(penguins$body_mass_g[penguins$species == "Adelie"])
lines(c(0.75, 0.75), rng, col=cols[1])
text(0.9, rng[2] + 100, "range", col=cols[1], pos=2)

iqr = quantile(penguins$body_mass_g[penguins$species == "Chinstrap"], c(0.25, 0.75))
lines(c(1.75, 1.75), iqr, col=cols[2])
text(1.75, iqr[2], "IQR", col=cols[2], pos=2)
med = median(penguins$body_mass_g[penguins$species == "Chinstrap"])
text(2.15, med, "median", col=cols[3], pos=4)

lines(c(2.75, 2.75), c(4950, 5150), col=cols[4])
text(2.75, 4950, "~95 % CI", col = cols[4], pos = 2)

text(1.7,5700, 
     "outliers\n x < quartile(x, 0.25) - 1.5*IQR(x)\n x > quartile(x, 0.75) + 1.5*IQR(x)", 
     pos=1, col=cols[5], cex=0.7)
lines(c(1.8, 2), c(5300, 4850), col = cols[5])
```

</div>





## More on boxplots

<div class="left lt">

* **Boxplots** (sometimes **box-and-whisker** diagrams) summarize key statistics.
	- median
	- first and third quartiles (hinges)
	- approx. 95% confidence interval for median (notch)
	- min/max (or quartile + 1.5*IQR) (whiskers)
* They are very useful for comparing variables among groups.
* Base graphics: we use the `boxplot` function
* `y ~ group` is a special data type called a `formula`

For more complex groupings, better to use `ggplot`

</div>

<div class="right rt">

```{r}
peng_bplot = ggplot(penguins, aes(y = body_mass_g, x = sex, 
                            fill = species)) + 
    geom_boxplot(notch = TRUE) + 
    theme_minimal() + ylab("Body Mass (g)") + xlab("") +
    scale_fill_brewer(palette = "Paired") 

peng_bplot
```


</div>





## Programming mini-lesson: repeating yourself

<div class="left lt">
* An important programming concept is **DRY**: Don't Repeat Yourself!
   - Don't copy and paste code if you can instead instruct the computer to repeat things for you.
* There are many ways to execute the same code repeatedly; we will cover these in detail as they are needed.
* A motivating example:
    - Compute the mean of every numeric variable in the `penguins` dataset

</div>

<div class="right rt">

```{r}
# bad!
(col_means = c(
  mean(penguins[,3]),
  mean(penguins[,4]),
  mean(penguins[,5]),
  mean(penguins[,3])  # it's easy to introduce mistakes this way!
))
```

</div>



## Applying functions

* We want to **apply** the function named `mean` separately to every variable in `penguins` 
* R has many different ways to apply functions, in this case we use `s`imple `apply` (`sapply`)

```{r}
# bad!
(col_means = c(
  mean(penguins[,3]),
  mean(penguins[,4]),
  mean(penguins[,5]),
  mean(penguins[,3])  # it's easy to introduce mistakes this way!
))

# better
# first we find out which columns are numeric
numeric_columns = sapply(penguins, is.numeric)

# then we get the means of those columns
(col_means = sapply(penguins[,numeric_columns], mean))
```



## Applying functions

* We want to **apply** the function named `mean` separately to every variable in `penguins` 
* R has many different ways to apply functions, in this case we use `s`imple `apply` (`sapply`)
* this works with any function that accepts a vector, even when they return more than a single value
```{r}
sapply(penguins[,numeric_columns], range)
# here, we pass an additional argument named probs to quantile
# see ?quantile for what this does
sapply(penguins[,numeric_columns], quantile, probs = c(0.25, 0.5, 0.75))
```







## Tabular applies

<div class="left lt">
* There are three species of penguin; it makes more sense to have summary statistics for each one
* `tapply`: `t`abular `apply`
  - produces a summary table for a single variable (e.g., `bill_length_mm`) based on categories in another variable (e.g., `species`)

</div>

<div class="right rt">

```{r}
# with: use the variables found in the data.frame penguins
with(penguins, 
	 # compute the mean of bill_length_mm for each of the three species
	 tapply(bill_length_mm, species, mean)
)
```

</div>


## Probability distributions

* We have shown several examples of curves we could describe a distribution of values.
* What does it mean exactly to say that a variable follows a probability distribution?
* How do these distributions arise in nature?

```{r prob_dist, fig.width = 19, echo = FALSE}
dat_curve = data.frame(x = seq(-3, 3, 0.1), y = dnorm(seq(-3, 3, 0.1)))
p_curve = ggplot(dat_curve) + geom_line(aes(x = x, y = y), col = 'red', linewidth = 2)
gridExtra::grid.arrange(peng_bplot, p1, p_curve, nrow = 1)

```

## Probability distributions

<div class="left lt">

**Thought experiment**

You and 99 of your closest friends gather on the centre line of a 100-m football pitch. We define the centre line as 0m, the western boundary -50 m, and the eastern boundary as +50 m.

</div>

<div class="right rt">

```{r echo=FALSE, fig.height=4, message = FALSE, warning = FALSE}
source("../vu_datenanalyse_students/unit_1/r/football.r")
players = rep(0, 100)
draw_pitch(players)
ggplot(data.frame(players = players), aes(x=players)) + geom_histogram(bins=40) + xlab("Player positions") + xlim(-50, 50)

```

</div>



## Probability distributions
<div class="left lt">

**Thought experiment**

You and 99 of your closest friends gather on the centre line of a 100-m football pitch. We define the centre line as 0m, the western boundary -50 m, and the eastern boundary as +50 m.

Each person flips a coin. If the coin is heads, they take a step east (add 0.5 m to their location), if its tails, they take a step west (subtract 0.5 m from their location). 

**Question**: What is the long-run distribution of positions on the field?


</div>

<div class="right rt">

```{r echo=FALSE, fig.height=4, warning = FALSE}
players = players + sample(c(-0.5, 0.5), length(players), replace = TRUE)
draw_pitch(players)
ggplot(data.frame(players = players), aes(x=players)) + geom_histogram(bins=200) + xlab("Player positions") + xlim(-50, 50)

```

</div>



## Probability distributions
<div class="left lt">

**Thought experiment**

You and 99 of your closest friends gather on the centre line of a 100-m football pitch. We define the centre line as 0m, the western boundary -50 m, and the eastern boundary as +50 m.

Each person flips a coin. If the coin is heads, they take a step east (add 0.5 m to their location), if its tails, they take a step west (subtract 0.5 m from their location). 

**Question**: What is the long-run distribution of positions on the field?

**Exercise**: Try to simulate this process in R. What does the distribution of locations look like after 10 steps? After 100? What is the long-run distribution with many steps and many players?


</div>

<div class="right rt">

```{r eval = FALSE}
# if you want to draw the soccer pitch, you can read the function for it
source("r/football.r")

# 100 players, all on the centre line (value = 0)
nplayers = 100
players = rep(0, nplayers)

# define the size of the steps for each coin flip
heads = 0.5
tails = -0.5

# simulate one step for each player
steps = sample(c(heads, tails), nplayers, replace = TRUE)

# update player locations
players = players + steps

# visualise, if desired
draw_pitch(players)
hist(players)
```

</div>





## Probability distributions
<div class="left lt">

**Thought experiment**

You and 99 of your closest friends gather on the centre line of a 100-m football pitch. We define the centre line as 0m, the western boundary -50 m, and the eastern boundary as +50 m.

Each person flips a coin. If the coin is heads, they take a step east (add 0.5 m to their location), if its tails, they take a step west (subtract 0.5 m from their location). 

**Question**: What is the long-run distribution of positions on the field?

**Exercise**: Try to simulate this process in R. What does the distribution of locations look like after 10 steps? After 100? What is the long-run distribution with many steps and many players?

```{r eval = FALSE}
# simulate 500 steps with 1000 players
nplayers = 1000
players = rep(0, nplayers)

for(i in 1:500) {
	steps = sample(c(heads, tails), nplayers, replace = TRUE)
	players = players + steps
}

# visualise, if desired
draw_pitch(players)
hist(players)
```


</div>

<div class="right rt">

```{r echo = FALSE}
# if you want to draw the soccer pitch, you can read the function for it
source("../vu_datenanalyse_students/unit_1/r/football.r")

# 100 players, all on the centre line (value = 0)
nplayers = 100
players = rep(0, nplayers)

# define the size of the steps for each coin flip
heads = 0.5
tails = -0.5


```

```{r echo = FALSE, fig.height = 4, warning = FALSE}
nplayers = 1000
players = rep(0, nplayers)

set.seed(1257)
for(i in 1:500) {
	steps = sample(c(heads, tails), nplayers, replace = TRUE)
	players = players + steps
}

# visualise, if desired
draw_pitch(players)
ggplot(data.frame(players=players), aes(x=players)) + geom_histogram(bins=20) + 
	xlab("Player positions") + xlim(-50, 50) + theme_minimal()
```

</div>





## Probability distributions: PDFs
<div class="left lt">
* We can rescale this histogram, such that the **area** of each bar represents the proportion of samples within that bin.

> - The height of each bar is the **probability density**.
> - The figure approximates an empirical **probability density function**.

</div>

<div class="right rt">
```{r}
hist(players, breaks=30, col="gray", main = "", freq=FALSE)
```

</div>




## Probability distributions: PDFs
<div class="left lt">
* We can rescale this histogram, such that the **area** of each bar represents the proportion of samples within that bin.
* The height of each bar is the **probability density**.
* The figure approximates an empirical **probability density function**.
* We can use the `density` function in R to add a curve approximating this density. 

</div>

<div class="right rt">
```{r}
hist(players, breaks=30, col="gray", main = "", freq=FALSE)
lines(density(players, adjust=1.5), col='red', lwd=2)
```

</div>






## Normal distributions
<div class="left lt">
* This looks a lot like a normal distribution.
* As we take smaller and smaller steps, and do more coin flips, the distribution of values will converge exactly on a normal distribution.
* Here we add a normal **PDF** based on the sample mean and sd (in blue).

</div>

<div class="right rt">
```{r}
hist(players, breaks=40, col="gray", main = "", freq=FALSE)
lines(density(players, adjust=1.5), col='red', lwd=2)
mu = mean(players)
sig = sd(players)
x_norm = seq(min(players), max(players), length.out = 400)
y_norm = dnorm(x_norm, mu, sig)
lines(x_norm, y_norm, lwd=2, col='blue')
legend("topright", legend=c(paste("sample mean =", round(mu, 2)), 
                            paste("sample sd =", round(sig, 2))), lwd=0, bty='n')
```

</div>







## Normal distributions

> - In nature, any process that involves summing small random values produces exactly this shape.
> - The distribution is **symmetric** and **unimodal**.
> - mean, median, mode are all equal.
> - The distribution has two **parameters**, the mean ($\mu$) and the standard deviation ($\sigma$).
> - If $\mu = 0$ and $\sigma = 1$, the distribution is called the **standard normal**.
> - Transforming a variable so that $\mu = 0$ and $\sigma = 1$ is called **standardization**.
$$
x_{std} = \frac{(x - \bar{x})}{s}\approx\frac{(x - \mu)}{\sigma}
$$
> - In R, we can use the `scale` function.






## Normal distributions

<div class="left lt">
* The typical "bell-curve" shape of the normal distribution is the Normal **Probability Density Function** (PDF)

$$
\mathcal{f}(x) = \frac{1}{\sigma \sqrt{2\pi}} \mathcal{e}^{-\frac{1}{2} \left (\frac{x-\mu}{\sigma} \right )^2}
$$

* It is easiest to understand what this function represents by understanding its **integral**.
* Recall that the area of each bar in our histogram represents the *proportion* of observations in that bin.


</div>

<div class="right rt">
```{r echo = FALSE}
hist(players, breaks=40, col="gray", main = "", freq=FALSE)
lines(x_norm, y_norm, lwd=2, col='blue')
legend("topright", legend=c(paste("sample mean =", round(mu, 2)), 
                            paste("sample sd =", round(sig, 2))), lwd=0, bty='n')
```

</div>






## Normal distributions: area under the curve

<div class="left lt">

* The integral between two values $a$ and $b$ is equal to the area under the curve.
* This is exactly the probability of observing a value between $a$ and $b$.
* Rule of thumb: about 68% of values in any normal distribution will be within 1 standard deviation of the mean.


</div>

<div class="right rt">
```{r echo = FALSE}
plot(0,0, xlim=range(x_norm), ylim=range(y_norm), xlab = "X", ylab = "Probability Density", bty="n", type='n')
x_poly = seq(mu-sig, mu+sig, length.out=200)
y_poly = dnorm(x_poly, mean(players), sd(players))
x_poly = c(x_poly, rev(x_poly))
y_poly = c(y_poly, rep(0, length(y_poly)))
polygon(x_poly, y_poly, col=cols[2])
lines(x_norm, y_norm, lwd=2, col='blue')
text(mu+c(sig, -sig), dnorm(mu+c(sig, -sig), mu, sig), c(expression(mu+sigma), expression(mu-sigma)), pos = c(4,2))

legcex = 0.7
legend("topright", cex = legcex, legend=c(paste("sample mean =", round(mu, 2)), 
                            paste("sample sd =", round(sig, 2)),
                            paste("area under curve =", round(diff(pnorm(mu+c(-sig, sig), mu, sig)), 4))), lwd=0, bty='n')
```
</div>







## Normal distributions: area under the curve

<div class="left lt">

* The integral between two values $a$ and $b$ is equal to the area under the curve.
* This is exactly the probability of observing a value between $a$ and $b$.
* Rule of thumb: about 68% of values in any normal distribution will be within 1 standard deviation of the mean.
* Rule of thumb: 95% of values are $\mu \pm 1.96 \sigma \approx \mu \pm 2 \sigma$.

</div>

<div class="right rt">
```{r echo = FALSE}
plot(0,0, xlim=range(x_norm), ylim=range(y_norm), xlab = "X", ylab = "Probability Density", bty="n", type='n')
x_poly = seq(mu-1.96*sig, mu+1.96*sig, length.out=200)
y_poly = dnorm(x_poly, mean(players), sd(players))
x_poly = c(x_poly, rev(x_poly))
y_poly = c(y_poly, rep(0, length(y_poly)))
polygon(x_poly, y_poly, col=cols[2])
polygon(x_poly, y_poly, col=cols[2])
lines(x_norm, y_norm, lwd=2, col='blue')
text(mu+c(1.96*sig, -1.96*sig), dnorm(mu+c(1.96*sig, -1.96*sig), mu, sig), 
     c(expression(mu+1.96*sigma), expression(mu-1.96*sigma)), pos = c(4,2))

legend("topright", cex = legcex, legend=c(paste("sample mean =", round(mu, 2)), 
                            paste("sample sd =", round(sig, 2)),
                            paste("area under curve =", round(diff(pnorm(mu+c(-1.96*sig, 1.96*sig), mu, sig)), 4))), lwd=0, bty='n')
```
</div>








## Normal distributions: CDF

<div class="left lt">
* If we integrate from  $-\infty$ to some value $x$, then we have the probability of observing a value **less than** $x$.
* This integral of the Normal PDF is known as the Normal **cumulative distribution function**.

$$
\mathcal{g}(x) = \int_{-\infty}^{x} \frac{1}{\sigma \sqrt{2\pi}} \mathcal{e}^{-\frac{1}{2} \left (\frac{x-\mu}{\sigma} \right )^2} dx
$$


```{r echo = FALSE}
```

</div>

<div class="right rt">


```{r echo = FALSE, fig.height = 8}
par(mfrow = c(2, 1))
	
plot(0,0, xlim=range(x_norm), ylim=range(y_norm), xlab = "X", ylab = "Probability Density", bty="n", type='n')
x_poly = seq(-50, mu-1.96*sig, length.out=100)
y_poly = dnorm(x_poly, mean(players), sd(players))
x_poly = c(x_poly, rev(x_poly))
y_poly = c(y_poly, rep(0, length(y_poly)))
polygon(x_poly, y_poly, col=cols[2])
lines(x_norm, y_norm, lwd=2, col='blue')
text(mu+-1.96*sig, dnorm(mu-1.96*sig, mu, sig), expression(mu-1.96*sigma), pos = 4)

legend("topright", cex = legcex, legend=c(paste("sample mean =", round(mu, 2)), 
                            paste("sample sd =", round(sig, 2)),
                            paste("area under curve =", round(pnorm(mu-1.96*sig, mu, sig), 4))), lwd=0, bty='n')

plot(0,0, xlim=range(x_norm), ylim=c(0,1), xlab = "X", ylab = "Cumulative Probability", bty="n", type='n')
lines(x_norm, pnorm(x_norm, mu, sig), lwd=2, col='red')


```


</div>






## Distributions in R
<div class="left lt">

* R has four functions in common for many families of distributions:

**PDF**: what is the probability `d`ensity when $x=3$ (the height of the bell curve)


```{r}
dnorm(x = 3, mean = mean(players), sd = sd(players))
```

</div>

<div class="right rt">


```{r norm_pdf_plot, echo = FALSE}
	
plot(0,0, xlim=range(x_norm), ylim=range(y_norm), xlab = "X", ylab = "Probability Density", bty="n", type='n')
lines(x_norm, y_norm, lwd=2, col='blue')
points(3, dnorm(x = 3, mean = mean(players), sd = sd(players)), pch = 16, col = 'red', cex=2)
```
</div>




## Distributions in R
<div class="left lt">

* R has four functions in common for many families of distributions:

**PDF**: what is the probability `d`ensity when $x=3$ (the height of the bell curve)

```{r}
dnorm(x = 3, mean = 0, sd = 1)
```

**CDF**: what is the cumulative `p`robability when $x=q$

(area under the bell curve from $-\infty$ to $q$)

(probability of observing a value < $q$)

```{r}
pnorm(q = mean(players) - 1.96 * sd(players), 
	  mean = mean(players), sd = sd(players))
```

</div>

<div class="right rt">

```{r pnorm_plot, echo = FALSE}
plot(0,0, xlim=range(x_norm), ylim=range(y_norm), xlab = "X", ylab = "Probability Density", bty="n", type='n')
x_poly = seq(-50, mu-1.96*sig, length.out=100)
y_poly = dnorm(x_poly, mean(players), sd(players))
x_poly = c(x_poly, rev(x_poly))
y_poly = c(y_poly, rep(0, length(y_poly)))
polygon(x_poly, y_poly, col=cols[2])
lines(x_norm, y_norm, lwd=2, col='blue')
text(mu+-1.96*sig, dnorm(mu-1.96*sig, mu, sig), expression(mu-1.96*sigma), pos = 4)

```
</div>


## Distributions in R

* R has four functions in common for many families of distributions:

**Quantiles**: what is the value of $x$, such that the probability of observing **x or smaller** is $p$

(inverse of the CDF/`pnorm`)

```{r}
qnorm(p = 0.025, mean = 0, sd = 1)
```

## Distributions in R

* R has four functions in common for many families of distributions:

**Quantiles**: what is the value of $x$, such that the probability of observing **x or smaller** is $p$

(inverse of the CDF/`pnorm`)

```{r}
qnorm(p = 0.025, mean = 0, sd = 1)
```

**RNG**: Random number generator, produces $n$ random numbers from the desired distribution

```{r}
rnorm(n = 10, mean= 0, sd = 1)
```





## Sampling error
> - In practise, we work with samples, which are imperfectly representative of the populations from which they are drawn.
> - The **sample mean** $(\bar{x})$ and **sample standard deviation** $(s)$ approximate the population $\mu$ and $\sigma$.
> - We would like to known how good our estimates are!
> - A **standard error** tells you how well a **sample statistic** represents the **population parameter**.
> - If you repeat your sampling many times, and compute a separate sample statistic each time (e.g., $\bar{x}$, $s$, etc)...
> - The sample statistics will converge on a normal distribution (if the sample size is large).
> - The **standard deviation of sample statistics** will equal the **standard error** of the statistic.

## Standard error of the mean
* In practise, we work with samples, which are imperfectly representative of the populations from which they are drawn
* The **sample mean** $(\bar{x})$ and **sample standard deviation** $(s)$ approximate the population $\mu$ and $\sigma$
* We would like to known how good our estimates are!
* A **standard error** tells you how well a **sample statistic** represents the **population parameter**.
* If you repeat your sampling many times, and compute a separate sample statistic each time (e.g., $\bar{x}$, $s$, etc)...
* The sample statistics will converge on a normal distribution (if the sample size is large)
* The **standard deviation of sample statistics** will equal the **standard error** of the statistic.
* We commonly use the **standard error of the mean** to make inferences about the mean of a sample
* A larger sample size results in a smaller standard error


$$
\sigma_{\bar{x}} = \frac{\sigma}{\sqrt{n}} \approx \frac{s}{\sqrt{n}}
$$




## Central limit theorem
* If you repeat your sampling many times, and compute a separate sample statistic each time (e.g., $\bar{x}$, $s$, etc)...
* The sample statistics will converge on a normal distribution (if the sample size is large).

> - This holds generally in many natural systems.
> - If a variable $x$ is normally distributed, then $\bar{x}$ will be normally distributed, regardless of sample size.
> - The farther $x$ is away from a normal distribution, the larger $n$ must be before $\bar{x}$ follows a normal distribution.
> - If $n$ is large enough...
> - $\bar{x}$ will be normally distributed with a mean = $\mu$ and standard deviation = the standard error of the mean.




