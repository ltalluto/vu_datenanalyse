---
title: "Worksheet 3"
author: "Matthew Talluto & Gabriel Singer"
date: "23.02.2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, error=TRUE)
```


## Hucho record captures in Austrian rivers

Fishermen like to catch record-breaking large fish and if successful will do a bit of effort to document their historic achievement in the local pub ;-) This dataset contains sizes of such record catches of Hucho in various Austrian streams and rivers of various size, the data was collected from various sources including the eventual black-and-white photograph hanging in a pub.

Here is one such picture from the author of the study:

![](img/Hucho.jpg)

The Danube salmon is an endangered species in now dwindling populations. It needs intact river corridors for migration. Hydropower facilities should have a fish ladder allowing the fish to bypass turbines. The size of such a fish ladder is a cost issue AND an ecological issue - it needs to be large enough to accommodate the expected fish size in any given system. Usually large rivers host large fish. So, river size could be taken as a proxy of fish size to be expected.

```{r}
hucho = read.table("data/HuchoRatschan2012.txt", header = TRUE)
getwd()
```

1. Look for a reasonable relationship of a river size measure with a fish size measure. Deliver a model that could guide construction of fish passes. Consider transformations to linearize relationships.
```{r}
names(hucho)
plot(length~width,data=hucho)
plot(mass~log(discharge),data=hucho) # I go for this one, but several others may also make sense
humo1<-lm(mass~log(discharge),data=hucho)
summary(humo1)
abline(humo1)
coef(humo1)
```
Hucho model1: fish mass = 14.9+2.4 * log(Q)


2. A potential confounding variable could be population size. When a population of Hucho is very small, it is less likely to contain large specimens. The dataset includes an estimate of population size based on expert (= fishermen) opinion. Explore differences in maximum Hucho body size captured in the various systems depending on population size. Test for differences and produce a publishable final graph showing average maximum fish size in dependence from population size. Don´t forget to check assumptions before running your statistical analysis and justify your choice of method.
```{r}
boxplot(mass~population,data=hucho)
# anova-problem
hist(hucho$mass[hucho$population=="limited"]) # ND will anyway be hard to judge...
qqnorm(hucho$mass[hucho$population=="limited"])
qqnorm(hucho$mass[hucho$population=="medium"])
qqnorm(hucho$mass[hucho$population=="large"])
hist(unlist(tapply(hucho$mass,INDEX=hucho$population,FUN=scale)))
qqnorm(unlist(tapply(hucho$mass,INDEX=hucho$population,FUN=scale)))
shapiro.test(unlist(tapply(hucho$mass,INDEX=hucho$population,FUN=scale))) # check ND
bartlett.test(mass~population,data=hucho) # check var.hom.
humo2<-lm(mass~population,data=hucho)
summary(humo2)
anova(humo2)
# Anova population size does not affect fish size significantly
pairwise.t.test(hucho$mass,hucho$population,method="bonferroni",pool.sd=TRUE)
# pairwise no significant difference!
```

Population size does not significantly influence maximum fish size (F=2.6, df1=2, df2=29, P=0.09), but there is a tendency for the limited populations to have smaller fish on average.

3. You will find that both river size and population size affect maximum Hucho size. How can you test both predictors at once? Which would be the best model for fish ladder builders if they wanted to improve the conservation status of Danube salmon in the future?
```{r}
hucho$population<-factor(hucho$population)
levels(hucho$population) # check order of levels
plot(mass~log(discharge),data=hucho,col=hucho$population)
abline(humo1)
boxplot(humo1$residuals~hucho$population) # this residual analysis strongly hints at an effect of population!
humo3<-lm(mass~log(discharge)*population,data=hucho)

summary(humo3)
anova(humo3)
humo4<-lm(mass~log(discharge)+population,data=hucho)
anova(humo4)
summary(humo4)

plot(length~log(discharge),data=hucho)

```
The best model to estimate fish ladder dimension comes from mass~log(Q) using only data from large populations:
Hucho model4: Fish mass = 16.67 +2.36 log(Q)
which has similar slope but higher intercept than the model that ignores population size:
Hucho model1: Fish mass = 14.9+2.4 * log(Q)
With model1 fish would be estimated too small, fish passes would not support the largest fish that we could hope for in eventually healthy populations.

## Solid particulate matter in lakes

Load the LakeSPM dataset (Lindström, M., Håkanson, L., Abrahamsson, O., Johansson, H. (1999) An empirical model for prediction of lake water suspended particulate matter. Ecological Modelling 121, 185–198).

```{r}
lakes <- read.table("data/LakeSPM.txt",header=TRUE)
```

The study has a set of lakes with SPM=solid particulate matter as the main response of interest. High SPM is a water quality issue, it can be generated through excessive phytoplankton growth or resuspension of sediment in shallow lakes or terrigeneous input into smaller lakes. For water quality prediction a model to predict SPM from easily accessible lake data should be generated. The available predictors include

* Measures of lake size and morphology that could influence sensitivity to terrestrial loading and resuspension of lake sediment.
* Measures of water renewal.
* Proxies for productivity.

1. Explore the data for potential relationships with the response SPM. Assess distributions and chance for collinearity by graphical means (e.g. using `pairs` or `plot(data)`). Consider appropriate transformation to improve linearity of relationships.
```{r}
plot(lakes[,-c(1:2)])
boxplot(scale(lakes[,-c(1:2)]))
#pH is already a log-transform, Vd seems symmetrically distributed, all others are skewed and are log-transformed
names(lakes)
lakes[,-c(1,2,7,12)]<-log(lakes[,-c(1,2,7,12)])
plot(lakes[,-c(1:2)])
boxplot(scale(lakes[,-c(1:2)]))
# distributions have improved, some linear relationships obvious - with response as well as among predictors (collinearity)
```

2. With `vif` from the `car`-package you can assess collinearity. Identify redundant variables using VIF and drop them from the dataset.
```{r}
lakes<-lakes[,-c(1:2)]
mlr.full<-lm(spm~.,data=lakes) # makes a model with all predictors available
library(car)
vif(mlr.full) #computes VIF
# check what VIF means:
summary(lm(area~.-spm,data=lakes)) # regressing area on all other predictors gives an R2 of (almost) 1!
# some really high VIF point to collinearity, start removing predictors and repeat procedure.

# full model without area
mlr.full<-lm(spm~.-area,data=lakes)
vif(mlr.full)
# full model without area and Dm
mlr.full<-lm(spm~.-area-Dm,data=lakes)
vif(mlr.full)
# -> still high VIFs for some predictors, drop Dmax

# full model without Dm and area and Dmax
mlr.full<-lm(spm~.-area-Dm-Dmax,data=lakes)
vif(mlr.full)
# -> now all predictors have VIF<10 and make sense as input for MLR

# delete the unnecessary predictors from the dataframe
which(names(lakes) %in% c("area","Dm","Dmax"))
lakes<-lakes[,-c(2,3,4)]
```
3. Identify the best **simple** linear regression model and a **full** model with only one predictor or all non-redundant ones to start a forward and a backward model building process.
```{r}
mlr.full<-lm(spm~.,data=lakes) # makes a model with all predictors available
summary(mlr.full)
# -> this is "maximum" model with lots of probably unimportant predictors, maximum "achievable" r2 is now 0.88

plot(lakes)

simple.mod1<-lm(spm~TP,data=lakes)
summary(simple.mod1)
plot(spm~TP,data=lakes)
abline(simple.mod1,col="red")
# -> very good relationship, high r2
```

4. Using the functions `add1`and `drop1` terms can be added to or removed from models. Follow a forward and a backward model building process until a final result and compare the two final models.
```{r}
add1(simple.mod1,scope=~pH+TP+T+Q+DR+Vd,test="F")
# -> pH and DR seem to be good candidates for adding to the model
# -> add pH (its inclusion alongside TP causes strongest change in model according to F-value and produces lowest AIC)
mlr1<-lm(spm~TP+pH,data=lakes)
summary(mlr1)
# -> good model, try adding more terms
add1(mlr1,scope~pH+TP+T+Q+DR+Vd,test="F")
# -> add DR
mlr2<-lm(spm~TP+pH+DR,data=lakes)
summary(mlr2)
# -> good model, all terms significant try adding more terms
add1(mlr2,scope~pH+TP+T+Q+DR+Vd,test="F")
# -> no  more terms to add according to F -> mlr2 is the final model (as in the original publication)
# -> not that according to AIC we could add Vd and keep building more complicated model

# alternatively with dropping terms from the full model
summary(mlr.full)
# -> unreasonable model with many insignificant terms
drop1(mlr.full,test="F")
# -> drop Q (lowest F, highest P, also makes lowest AIC)
mlr3<-lm(spm~pH+TP+T+DR+Vd,data=lakes)
summary(mlr3)
drop1(mlr3,test="F")
# -> drop T
mlr4<-lm(spm~pH+TP+DR+Vd,data=lakes)
summary(mlr4)
drop1(mlr4,test="F")
# according to F we should drop pH, according to AIC this is already the best model
# rule of thumb: AIC differences <2 are not reliable, thus drop pH
mlr5<-lm(spm~TP+DR+Vd,data=lakes)
summary(mlr5)
drop1(mlr5,test="F")
# -> no more terms to drop
# -> final model is different between forward and backward variable selection, even though 2 of 3 predictors are identical!

```
5. Use `step` to identify a *good* model based on the AIC. How does this compare to the models created above? Check model assumptions and decide for a final model.
```{r}
step(mlr.full,direction="backward")
step(simple.mod1,scope=~pH+TP+T+Q+DR+Vd,direction="forward")
# same solutions! compare with selection by F!

# combined forward and backward selection based on AIC
step(mlr.full,direction="both")
mlr8<-lm(spm~pH+TP+DR+Vd,data=lakes)

# assess the final model candidates: mlr2, mlr5 and mlr8
summary(mlr2)
summary(mlr5)
summary(mlr8)
extractAIC(mlr2)
extractAIC(mlr5)
extractAIC(mlr8)
# -> r2 and AIC are not very different, not enough reason to use more complex model (4 vs. 3 variables!)
# AIC differences between models <2 indicate "equivalent" models
# -> choose mlr2 or mlr5

```

6. The model is intended to be used for prediction. Test its prediction capacity using a leave-1-out approach. Leave-1-out means to predict the response for each observation with a model built without this observation. For this, pick your most favourite model built above. Use a loop to leave out 1 case at a time, then predict for the left-out case. Finally compare observed vs. (unbiased) predictions and plot on a 1:1 graph.


```{r}
# will use mlr2
i = 1
ypred_cv<-rep(NA,nrow(lakes))
for(i in 1:nrow(lakes)) {
  mod <- lm(spm ~ TP + pH + DR, data = lakes[-i, ])
  ypred_cv[i]<-predict(mod, newdata = lakes[i,])
}
plot(lakes$spm,ypred_cv)
abline(a=0,b=1,col="red")
cor.test(lakes$spm,ypred_cv)
```

> conclude: mlr2 is able to make reasonably good predictons even for left-out cases

## Mortality/Abundacne of sugar maple

These data are from a study of the response of trees in North America to climate change (Talluto, et al. (2017) Extinction debt and colonization credit delay range shifts of eastern North American trees. Nat Ecol Evol 1, 0182 (2017). https://doi.org/10.1038/s41559-017-0182).

Load the somewhat deconstructed dataset, containing climate data, data on tree abundance and mortality, and a species table:

```{r}
clim = read.csv("data/tree_clim.csv")
trees = read.csv("data/trees.csv")
species = read.csv("data/tree_species.csv")
```

We have two potential hypotheses to explore:

**1**: Mortality of sugar maple (*Acer saccharum*) is negatively related to temperature and/or climatic variability.

**2**: Abundance of sugar maple has a hump-shaped (quadratic) relationship to climate (i.e., there is a climatic optimum)

Choose one of the two to work on. 1 implies a binomial process (k trees died out of n trees present), and will have `cbind(died, n)` as the response variable. 2 implies a poisson process and will have `n` as the response. Formulate a more specific alternative hypothesis.

### Reshaping

The data will need to be reshaped a bit before use.

1. Explore the climate data. Use `reshape2::dcast` to produce a "wide" format dataset. You have 6 variables, measured in plots across multiple years. 

**Measures of climate location**

* annual_mean_temp
* mean_temp_wettest_quarter
* tot_annual_pp (precipitation)
* pp_warmest_quarter

**Measures of climate variability**

* mean_diurnal_range
* pp_seasonality

Multicollinearity is usually a problem with climate variables, because many variables measure very similar things. However, the data set is very large, and so variance inflation is somewhat less of a problem. You should still choose a smaller number of variables to test (max 4); justify this choice based on a hypothesis. You can use `cor(clim[, -c(1,2)])` to make a correlation matrix; if two variables have a correlation > 0.6, you should only use one of them. You may (optionally) also check VIFs, but you should do so after fitting the model.

```{r}
library(reshape2)
clim_wide = dcast(clim, plot_id+year_measured ~ variable)
cor(clim_wide[,-(1:2)])

```

> I will select 4 variables, 1 each of temperature and precipitation, location and variability. I start with the variability, since there are only 2 variables I select them both (mean_diurnal_range and pp_seasonality). For temperature location, mean_temp_wettest_quarter is strongly correlated with pp_seasonaility, so I go with annual_mean_temp. For precipitation, pp_warmest_quarter is the most unique variable remaining, and has the added benefit of having a nice interpretation with regard to drought stress (low pp_warmest_quarter = high drought stress).

```{r}
## note that it is less error-prone if you refer to variables by name.
vars = c("plot_id", "year_measured", "annual_mean_temp", "mean_diurnal_range", "pp_seasonality", "pp_warmest_quarter")
my_clim_vars = clim_wide[, vars]
```



2. Merge the climate data with the tree data (as shown in the lecture), and filter the data to only include *Acer saccharum*

```{r}
trees = merge(trees, my_clim_vars, by.x = c("plot", "year"), 
              by.y= c("plot_id", "year_measured"))
trees = subset(trees, species_code == "28731-ACE-SAC") ## this is the species code for sugar maple
```


3. Fit GLMs (using the `glm` function with the `family = poisson` or `family = 'binomial'` option, depending on your response). Use `AIC(mod)` to compare different hypotheses about which variables to include. Choose a final 'best' model, and report the results using appropriate tables, figures, etc. If you use a poisson model, be sure to check for overdispersion in each of your models (it is not necessary to correct if it is too high in your final model, but do report it).


### Hypothesis 1

> Binomial models need to know what the count of events is (here, deaths, because we are modelling mortality), but they also need to know the number of "trials;" in this case, we can't observe more deaths than there were actual trees, so the variable is n. We use this to make a combined response variable: cbind(died, n)


```{r}
## biggest model, including all variables
mod_h1_1 = glm(cbind(died, n) ~ annual_mean_temp + mean_diurnal_range + pp_seasonality + pp_warmest_quarter, data = trees, family=binomial)
## only location, no variability
mod_h1_2 = glm(cbind(died, n) ~ annual_mean_temp + pp_warmest_quarter, data = trees, family=binomial)
## variability only
mod_h1_3 = glm(cbind(died, n) ~ mean_diurnal_range + pp_seasonality, data = trees, family=binomial)
## temperature only
mod_h1_4 = glm(cbind(died, n) ~ annual_mean_temp + mean_diurnal_range, data = trees, family=binomial)
## With all 2-way interactions
mod_h1_int = glm(cbind(died, n) ~ (annual_mean_temp + mean_diurnal_range + pp_seasonality + pp_warmest_quarter)^2, data = trees, family=binomial)


mods_h1 = data.frame(model = c("mod_h1_1", "mod_h1_2", "mod_h1_3", "mod_h1_4", "mod_h1_int"), 
					 aic = c(AIC(mod_h1_1), AIC(mod_h1_2), AIC(mod_h1_3), 
					 		AIC(mod_h1_4), AIC(mod_h1_int)))
mods_h1$dAIC = mods_h1$aic - min(mods_h1$aic)
mods_h1

coef(mod_h1_1)


new_trees = trees
new_trees[, c("annual_mean_temp", "mean_diurnal_range", "pp_seasonality", "pp_warmest_quarter")] = 
	scale(new_trees[, c("annual_mean_temp", "mean_diurnal_range", "pp_seasonality", "pp_warmest_quarter")])
mod_h1_1_sc = glm(cbind(died, n) ~ annual_mean_temp + mean_diurnal_range + pp_seasonality + pp_warmest_quarter, data = new_trees, family=binomial)
```

> The first model, with all 4 variables, is best. looking at the coefficients, we find that more variability in climate results in increased mortality. We can make response curves by generating some fake data. We set other variables to their mean when computing the predictions.

```{r}
x_plot = data.frame(annual_mean_temp = seq(min(trees$annual_mean_temp), max(trees$annual_mean_temp), length.out = 500), 
					mean_diurnal_range = mean(trees$mean_diurnal_range), pp_seasonality = mean(trees$pp_seasonality), 
					pp_warmest_quarter = mean(trees$pp_warmest_quarter))
# use the predict function to find out what we expect for mortality if x takes hypothetical values
# type = 'response' takes care of transforming away the link function, otherwise we would get predictions on the logit scale
y_plot = predict(mod_h1_1, type='response', newdata = x_plot)

par(mfrow = c(2,2), bty='n')
plot(x_plot$annual_mean_temp, y_plot, type='l', xlab='Annual Mean Temperature', ylab = "Mortality Probability", ylim=c(0,1), col='blue', lwd=2)
points(trees$annual_mean_temp, trees$died/trees$n, pch=16, cex=0.4)

## now just edit the appropriate columns to make the rest of the plots
for(i in 2:4) {
	nm = colnames(x_plot)[i]
	nm_pr = colnames(x_plot)[i-1]
	x_plot[,nm_pr] = mean(trees[,nm_pr]) # set the previous column to the mean
	# set the next to a sequence
	x_plot[, nm] = seq(min(trees[,nm]), max(trees[,nm]), length.out = 500)
	y_plot = predict(mod_h1_1, type='response', newdata = x_plot)
	plot(x_plot[,nm], y_plot, type='l', xlab=nm, ylab = "Mortality Probability", ylim=c(0,1), col='blue', lwd=2)
	points(trees[,nm], trees$died/trees$n, pch=16, cex=0.4)

}


```



### Hypothesis 2

> Here we check for hump-shaped relationships between the number of trees and climate. The number of trees is a count, so we use a Poisson model. I choose only to include quadratic terms for climate location; it makes sense that variability is either good or bad, not necessarily that there is an interpediate optimum.

```{r}
## biggest model, including all variables and a squared term for location
mod_h2_1 = glm(n  ~ annual_mean_temp + mean_diurnal_range + pp_seasonality + pp_warmest_quarter + I(annual_mean_temp^2) + I(pp_warmest_quarter^2), data = trees, family=poisson)
## only location, no variability
mod_h2_2 = glm(n ~ annual_mean_temp + pp_warmest_quarter + I(annual_mean_temp^2) + I(pp_warmest_quarter^2), data = trees, family=poisson)
## location, linear only
mod_h2_3 = glm(n ~ annual_mean_temp + pp_warmest_quarter, data = trees, family=poisson)
## temperature only
mod_h2_4 = glm(n  ~ annual_mean_temp + mean_diurnal_range + I(annual_mean_temp^2), data = trees, family=poisson)

mods_h2 = data.frame(model = c("mod_h2_1", "mod_h2_2", "mod_h2_3", "mod_h2_4"), 
					 aic = c(AIC(mod_h2_1), AIC(mod_h2_2), AIC(mod_h2_3), AIC(mod_h2_4)))
mods_h2$dAIC = mods_h2$aic - min(mods_h2$aic)
mods_h2

coef(mod_h2_1)
```

> The first model, with all 4 variables, is by far the best. looking at the coefficients, we find that more variability in climate results in increased mortality. Interpreting the coefficients directly with such a model is difficult, we will need to check the response curves.

```{r}
x_plot = data.frame(annual_mean_temp = seq(min(trees$annual_mean_temp), max(trees$annual_mean_temp), length.out = 500), 
					mean_diurnal_range = mean(trees$mean_diurnal_range), pp_seasonality = mean(trees$pp_seasonality), 
					pp_warmest_quarter = mean(trees$pp_warmest_quarter))
# use the predict function to find out what we expect for mortality if x takes hypothetical values
# type = 'response' takes care of transforming away the link function, otherwise we would get predictions on the logit scale
y_plot = predict(mod_h2_1, type='response', newdata = x_plot)

par(mfrow = c(2,2), bty='n')
plot(x_plot$annual_mean_temp, y_plot, type='l', xlab='Annual Mean Temperature', ylab = "Expected Number of Trees")

## now just edit the appropriate columns to make the rest of the plots
for(i in 2:4) {
	nm = colnames(x_plot)[i]
	nm_pr = colnames(x_plot)[i-1]
	x_plot[,nm_pr] = mean(trees[,nm_pr]) # set the previous column to the mean
	# set the next to a sequence
	x_plot[, nm] = seq(min(trees[,nm]), max(trees[,nm]), length.out = 500)
	y_plot = predict(mod_h2_1, type='response', newdata = x_plot)
	plot(x_plot[,nm], y_plot, type='l', xlab=nm, ylab = "Expected Number of Trees")
}

```

> The quadratic terms produce some rather unexpected predictions. In particular, not only do we find no evidence of an optimum, but there is an anti-optimum with regards to precipitation! The model predicts the least number of trees at intermediate precipitations. Likely we have not done an adequate job building this model, and so we will need to explore further hypotheses...

> But for the moment, we have another problem. Poisson models assume the variance is equal to the mean. We can check this with the "dispersion parameter," which should be equal to one. Compute it as the ratio of residual deviance to the degrees of freedom. For comparison, we can do this for all models.

```{r}
mod_h2_1$deviance / mod_h2_1$df.residual
mod_h2_2$deviance / mod_h2_2$df.residual
mod_h2_3$deviance / mod_h2_3$df.residual
mod_h2_4$deviance / mod_h2_4$df.residual

```

> As the models get simpler, the dispersion parameter gets worse (simpler models describe less deviance). In all cases, the dispersion parameters are quite a bit greater than one, so (in a complete analysis), we would need to consider more variables, or consider another model structure. Unfortunately, the counts are much too close to zero to use a normal approximation.

```{r}
hist(trees$n)
```

